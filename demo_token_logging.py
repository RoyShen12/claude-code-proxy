#!/usr/bin/env python3
"""
æ¼”ç¤º Token Usage Logging åŠŸèƒ½
å±•ç¤ºå¦‚ä½•åœ¨consoleä¸­æŸ¥çœ‹tokenä½¿ç”¨æƒ…å†µ
"""

import json
import sys
from pathlib import Path

def demonstrate_token_logging():
    """æ¼”ç¤ºtoken loggingåŠŸèƒ½çš„é…ç½®å’Œæ•ˆæœ"""

    print("ğŸ¯ Token Usage Logging åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)

    print("ğŸ“‹ åŠŸèƒ½è¯´æ˜:")
    print("â€¢ å½“ä¸‹æ¸¸APIè¿”å›token usageä¿¡æ¯æ—¶ï¼Œä»£ç†ä¼šåœ¨consoleè¾“å‡ºINFOçº§åˆ«æ—¥å¿—")
    print("â€¢ æ”¯æŒstreamingå’Œnon-streamingä¸¤ç§è¯·æ±‚ç±»å‹")
    print("â€¢ æ˜¾ç¤ºæ¨¡å‹æ˜ å°„ã€è¾“å…¥è¾“å‡ºtokenæ•°é‡å’Œæ€»è®¡")
    print("")

    print("âš™ï¸ é…ç½®è¦æ±‚:")
    print("1. è®¾ç½® LOG_LEVEL=INFO æˆ– LOG_LEVEL=DEBUG")
    print("2. ç¡®ä¿ä¸‹æ¸¸APIæ”¯æŒè¿”å›usageä¿¡æ¯")
    print("3. å¯¹äºstreamingè¯·æ±‚ï¼Œéœ€è¦ stream_options: {include_usage: true}")
    print("")

    print("ğŸ”§ .env é…ç½®ç¤ºä¾‹:")
    print("```")
    print("LOG_LEVEL=INFO")
    print("DEFAULT_MAX_TOKENS=1024")
    print("MAX_TOKENS_LIMIT=4096")
    print("```")
    print("")

    print("ğŸ“Š Consoleè¾“å‡ºç¤ºä¾‹:")
    print("```")
    print("2025-07-01 15:30:15 - INFO - ğŸ¯ Token Usage | Model: claude-3-haiku â†’ gpt-4o-mini | Input: 15 | Output: 42 | Total: 57")
    print("2025-07-01 15:30:20 - INFO - ğŸ¯ Token Usage [Stream] | Model: claude-3-sonnet | Input: 23 | Output: 156 | Total: 179")
    print("2025-07-01 15:30:25 - INFO - ğŸ¯ Token Usage [Stream+Cancel] | Model: claude-3-opus | Input: 45 | Output: 203 | Total: 248")
    print("```")
    print("")

    print("ğŸ§ª æµ‹è¯•æ–¹æ³•:")
    print("1. å¯åŠ¨ä»£ç†æœåŠ¡å™¨:")
    print("   python start_proxy.py")
    print("")
    print("2. å‘é€æµ‹è¯•è¯·æ±‚:")
    print("   python test_token_logging.py")
    print("")
    print("3. è§‚å¯Ÿconsoleè¾“å‡ºä¸­çš„token usageæ—¥å¿—")
    print("")

    print("ğŸ“ æ—¥å¿—æ ¼å¼è¯´æ˜:")
    log_formats = [
        {
            "ç±»å‹": "Non-streaming",
            "æ ¼å¼": "ğŸ¯ Token Usage | Model: {source} â†’ {target} | Input: {input} | Output: {output} | Total: {total}",
            "è§¦å‘": "æ™®é€šAPIè°ƒç”¨å®Œæˆæ—¶"
        },
        {
            "ç±»å‹": "Streaming",
            "æ ¼å¼": "ğŸ¯ Token Usage [Stream] | Model: {source} | Input: {input} | Output: {output} | Total: {total}",
            "è§¦å‘": "æµå¼APIè°ƒç”¨çš„æœ€ç»ˆtokenç»Ÿè®¡æ—¶"
        },
        {
            "ç±»å‹": "Streaming+Cancel",
            "æ ¼å¼": "ğŸ¯ Token Usage [Stream+Cancel] | Model: {source} | Input: {input} | Output: {output} | Total: {total}",
            "è§¦å‘": "æ”¯æŒå–æ¶ˆçš„æµå¼APIè°ƒç”¨å®Œæˆæ—¶"
        }
    ]

    for fmt in log_formats:
        print(f"â€¢ {fmt['ç±»å‹']}: {fmt['è§¦å‘']}")
        print(f"  æ ¼å¼: {fmt['æ ¼å¼']}")
        print()

    print("ğŸ’¡ æ³¨æ„äº‹é¡¹:")
    print("â€¢ åªæœ‰å½“input_tokens > 0 æˆ– output_tokens > 0æ—¶æ‰ä¼šè®°å½•æ—¥å¿—")
    print("â€¢ æ—¥å¿—çº§åˆ«å¿…é¡»è®¾ç½®ä¸ºINFOæˆ–DEBUGæ‰èƒ½çœ‹åˆ°")
    print("â€¢ å¦‚æœä¸‹æ¸¸APIä¸è¿”å›usageä¿¡æ¯ï¼Œå°†ä¸ä¼šæœ‰tokenæ—¥å¿—")
    print("â€¢ streamingè¯·æ±‚éœ€è¦stream_optionsæ”¯æŒæ‰èƒ½è·å–tokenä¿¡æ¯")

    print("\nğŸ¯ å®é™…ä»£ç ä½ç½®:")
    print("â€¢ Non-streaming: src/conversion/response_converter.py:convert_openai_to_claude_response()")
    print("â€¢ Streaming: src/conversion/response_converter.py:convert_openai_streaming_to_claude*()")

if __name__ == "__main__":
    demonstrate_token_logging()
